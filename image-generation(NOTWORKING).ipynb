{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image Generation w/ Hugging Face"
      ],
      "metadata": {
        "id": "HHFHIGhjYm1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install diffusers datasets transformers accelerate scipy ftfy\n",
        "\n",
        "import datasets\n",
        "import diffusers\n",
        "import huggingface_hub\n",
        "import torch\n",
        "from diffusers import DDPMPipeline\n",
        "from PIL import Image\n",
        "from datasets import load_dataset\n",
        "from torchvision import transforms\n",
        "from diffusers import DDPMScheduler\n",
        "from diffusers import UNet2DModel\n",
        "from torch.nn import functional as F\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Suppress warnings\n",
        "datasets.logging.set_verbosity_error()\n",
        "diffusers.logging.set_verbosity_error()\n",
        "huggingface_hub.logging.set_verbosity_error()\n",
        "\n",
        "# Load your own dataset\n",
        "dataset = load_dataset(\"lucabaggi/animal-wildlife\", split=\"train\")  # Example dataset, replace with your dataset\n",
        "\n",
        "\n",
        "# Create a subset of the first 256 images\n",
        "dataset = dataset.select(range(256))\n",
        "\n",
        "# Check the length of the subset\n",
        "print(f\"Length of the subset: {len(dataset)}\")\n",
        "\n",
        "# Preprocessing\n",
        "image_size = 16\n",
        "preprocess = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((image_size, image_size)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5], [0.5]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "def transform(examples):\n",
        "    examples[\"pixel_values\"] = [preprocess(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
        "    return examples\n",
        "\n",
        "# Apply the transform to the dataset\n",
        "dataset.set_transform(transform)\n",
        "\n",
        "# Create a custom dataset class to return tensors directly\n",
        "class TensorDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, hf_dataset):\n",
        "        self.hf_dataset = hf_dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.hf_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.hf_dataset[idx][\"pixel_values\"]  # Return tensor directly\n",
        "\n",
        "# Wrap the dataset in the custom class\n",
        "tensor_dataset = TensorDataset(dataset)\n",
        "\n",
        "# Create dataloader\n",
        "batch_size = 16\n",
        "train_dataloader = torch.utils.data.DataLoader(tensor_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Model and scheduler\n",
        "model = UNet2DModel(\n",
        "    sample_size=image_size,\n",
        "    in_channels=3,\n",
        "    out_channels=3,\n",
        "    layers_per_block=2,\n",
        "    block_out_channels=(32, 64, 128, 256),  # Number of channels in each block\n",
        "    down_block_types=(\n",
        "        \"DownBlock2D\",     # Downsampling blocks\n",
        "        \"DownBlock2D\",\n",
        "        \"AttnDownBlock2D\", # Downsampling blocks with attention\n",
        "        \"AttnDownBlock2D\",\n",
        "    ),\n",
        "    up_block_types=(\n",
        "        \"AttnUpBlock2D\",   # Upsampling blocks with attention\n",
        "        \"AttnUpBlock2D\",\n",
        "        \"UpBlock2D\",       # Upsampling blocks\n",
        "        \"UpBlock2D\"),\n",
        ").to(\"cuda\")\n",
        "\n",
        "noise_scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10  # Adjust as needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        clean_images = batch.to(\"cuda\")  # Move batch to GPU\n",
        "        noise = torch.randn(clean_images.shape).to(\"cuda\")\n",
        "        timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (batch_size,), device=\"cuda\").long()\n",
        "        noisy_images = noise_scheduler.add_noise(clean_images, noise, timesteps)\n",
        "\n",
        "        noise_pred = model(noisy_images, timesteps).sample\n",
        "        loss = F.mse_loss(noise_pred, noise)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Epoch {epoch}, Step {step}: Loss = {loss.item()}\")\n",
        "\n",
        "# Save the model\n",
        "# Replace with your desired path\n",
        "torch.save(model.state_dict(), \"animal_diffusion_model.pth\")"
      ],
      "metadata": {
        "id": "8d9B2sCQjTu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7503c9e1-2363-49c6-916d-ab047c7604d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: diffusers in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.32.2)\n",
            "Requirement already satisfied: datasets in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.3.2)\n",
            "Requirement already satisfied: transformers in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.49.0)\n",
            "Requirement already satisfied: accelerate in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.4.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.15.2)\n",
            "Requirement already satisfied: ftfy in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (6.3.1)\n",
            "Requirement already satisfied: importlib-metadata in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers) (8.6.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers) (0.29.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers) (2.2.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers) (0.5.2)\n",
            "Requirement already satisfied: Pillow in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from diffusers) (11.1.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: packaging in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from accelerate) (2.6.0+cu126)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.23.2->diffusers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->diffusers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->diffusers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->diffusers) (2025.1.31)\n",
            "Requirement already satisfied: networkx in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2.0.0->accelerate) (3.1.5)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\norri\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\norri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the subset: 256\n",
            "Epoch 0, Step 0: Loss = 1.1952087879180908\n",
            "Epoch 1, Step 0: Loss = 1.0711097717285156\n",
            "Epoch 2, Step 0: Loss = 0.9858610033988953\n",
            "Epoch 3, Step 0: Loss = 0.9025115966796875\n",
            "Epoch 4, Step 0: Loss = 0.8515722155570984\n",
            "Epoch 5, Step 0: Loss = 0.7744954824447632\n",
            "Epoch 6, Step 0: Loss = 0.7035807371139526\n",
            "Epoch 7, Step 0: Loss = 0.6628350019454956\n",
            "Epoch 8, Step 0: Loss = 0.6273400783538818\n",
            "Epoch 9, Step 0: Loss = 0.6010912656784058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the length of the dataset\n",
        "print(f\"Length of the dataset: {len(dataset)}\")\n",
        "\n",
        "# Visualize some images from the dataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_images(dataset, num_images=5):\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
        "    for i in range(num_images):\n",
        "        # Get an image from the dataset\n",
        "        image = dataset[i][\"pixel_values\"]  # Access the preprocessed tensor\n",
        "        # Convert tensor to numpy and denormalize\n",
        "        image = image.permute(1, 2, 0).cpu().numpy()  # Change from (C, H, W) to (H, W, C)\n",
        "        image = (image * 0.5) + 0.5  # Denormalize from [-1, 1] to [0, 1]\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Visualize 5 images\n",
        "visualize_images(dataset, num_images=8)"
      ],
      "metadata": {
        "id": "n4xK-I5QZCQg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "dbd6535c-cdd7-4a82-a728-3d19a6f7a76a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of the dataset: 256\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 8 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate images from the trained model"
      ],
      "metadata": {
        "id": "_rQ45b-0ZGiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import DDPMScheduler\n",
        "from diffusers import UNet2DModel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the trained model\n",
        "model = UNet2DModel(\n",
        "    sample_size=16,  # Match the image size used during training\n",
        "    in_channels=3,\n",
        "    out_channels=3,\n",
        "    layers_per_block=2,\n",
        "    block_out_channels=(32, 64, 128, 256),  # Number of channels in each block\n",
        "    down_block_types=(\n",
        "        \"DownBlock2D\",     # Downsampling blocks\n",
        "        \"DownBlock2D\",\n",
        "        \"AttnDownBlock2D\", # Downsampling blocks with attention\n",
        "        \"AttnDownBlock2D\",\n",
        "    ),\n",
        "    up_block_types=(\n",
        "        \"AttnUpBlock2D\",   # Upsampling blocks with attention\n",
        "        \"AttnUpBlock2D\",\n",
        "        \"UpBlock2D\",       # Upsampling blocks\n",
        "        \"UpBlock2D\"),\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Load the saved model weights\n",
        "model.load_state_dict(torch.load(\"animal_diffusion_model.pth\"))\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Set up the noise scheduler\n",
        "noise_scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
        "\n",
        "# Function to generate images\n",
        "def generate_images(num_images=1):\n",
        "    with torch.no_grad():  # Disable gradient computation\n",
        "        # Start from random noise\n",
        "        noise = torch.randn((num_images, 3, 256, 256)).to(\"cuda\")  # Match input dimensions\n",
        "        images = noise\n",
        "\n",
        "        # Denoising loop\n",
        "        for t in noise_scheduler.timesteps:\n",
        "            # Predict the noise residual\n",
        "            noise_pred = model(images, t).sample\n",
        "\n",
        "            # Compute the previous noisy sample x_t-1\n",
        "            images = noise_scheduler.step(noise_pred, t, images).prev_sample\n",
        "\n",
        "        # Convert images to CPU and denormalize\n",
        "        images = images.detach().cpu()\n",
        "        images = (images * 0.5) + 0.5  # Denormalize from [-1, 1] to [0, 1]\n",
        "        images = torch.clamp(images, 0, 1)  # Clamp to valid pixel range\n",
        "        return images\n",
        "\n",
        "# Generate and visualize images\n",
        "num_images = 50\n",
        "generated_images = generate_images(num_images)\n",
        "\n",
        "# Plot the generated images\n",
        "fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
        "for i, img in enumerate(generated_images):\n",
        "    img = img.permute(1, 2, 0)  # Change from (C, H, W) to (H, W, C)\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O_UClDznZVbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Create a directory to save the images\n",
        "os.makedirs(\"images\", exist_ok=True)\n",
        "\n",
        "# Plot and save the generated images\n",
        "fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
        "for i, img in enumerate(generated_images):\n",
        "    img = img.permute(1, 2, 0)  # Change from (C, H, W) to (H, W, C)\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "    # Save each image with a zero-padded two-digit number\n",
        "    filename = f\"images/animal_{i:02d}.png\"\n",
        "    plt.imsave(filename, img.numpy())\n",
        "\n",
        "# Save the entire grid of images\n",
        "plt.savefig(\"images/animal_grid.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r8S7ReetBggn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "1061c680-c811-4d98-90b7-6817f11fa74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'num_images' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4cbcb2ed792f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Plot and save the generated images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Change from (C, H, W) to (H, W, C)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf images/\n",
        "\n",
        "# Utility to zip a file\n",
        "import shutil\n",
        "shutil.make_archive(\"animals\", \"zip\", \"images\")"
      ],
      "metadata": {
        "id": "TYi9Eh0PHA_c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4ae2a68b-a29f-4103-f1bc-be9ed23204bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/animals.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}
